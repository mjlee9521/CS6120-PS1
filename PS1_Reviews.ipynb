{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PS1-Reviews.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPniszl33szJQSD18zFgGV/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mutherr/CS6120-PS1/blob/master/PS1_Reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un-XooBIC2zt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import requests\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate,KFold,LeaveOneOut\n",
        "from sklearn.preprocessing import scale\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkfdQFWZC542",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read in the movie review corpus\n",
        "def readReviews():\n",
        "  raw = requests.get(\"https://raw.githubusercontent.com/mutherr/CS6120-PS1-data/master/cornell_reviews.json\").text.strip()\n",
        "  corpus = [json.loads(line) for line in raw.split(\"\\n\")]\n",
        "  return corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjlLr0ayRDFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here is where you will featurize the data.\n",
        "#NB: The current contents are for testing only\n",
        "#This function should return: \n",
        "#  -a numpy matrix of document features\n",
        "#  -a list of the correct class for each document\n",
        "#  -a list of the vocabulary used by the features, such that the ith term of the\n",
        "#    list is the word whose counts appear in the ith column of the matrix. \n",
        "def createFeatures(corpus):\n",
        "  from sklearn.feature_extraction.text import CountVectorizer\n",
        "  import string\n",
        "\n",
        "  texts = [entry[\"text\"] for entry in corpus]\n",
        "  genres = [entry[\"class\"] for entry in corpus]\n",
        "\n",
        "  vectorizer = CountVectorizer()\n",
        "  texts = vectorizer.fit_transform(texts).todense()\n",
        "  vocab = vectorizer.get_feature_names()\n",
        "\n",
        "  return texts,genres,vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irJ8CxYJREoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#given a numpy matrix representation of the features for the training set, the \n",
        "# vector of true classes for each example, and the vocabulary as described \n",
        "# above, this computes the accuracy of the model using leave 10-fold cv\n",
        "# validation and reports the most indicative features for each class\n",
        "def evaluateModel(X,y,vocab,penalty=\"l1\"):\n",
        "  X = scale(X)\n",
        "  #create and fit the model\n",
        "  #This model literally will not fit to this data. The liblinear solver doesn't \n",
        "  # even try to update its parameters at all, saga and lbfgs run out of\n",
        "  # iterations and learn nothing. Even when I use a smaller dataset (10%) of the\n",
        "  # data (the same url but with cornell_reviews_small.json), it doesn't work.\n",
        "  model = LogisticRegression(penalty=penalty,max_iter=1000,solver=\"saga\",verbose=True)\n",
        "  results = cross_validate(model,X,y,cv=KFold(n_splits=5,shuffle=True))\n",
        "\n",
        "  #determine the average accuracy\n",
        "  scores = results[\"test_score\"]\n",
        "  avg_score = sum(scores)/len(scores)\n",
        "  print(scores)\n",
        "\n",
        "  #determine the most informative features\n",
        "  # this requires us to fit the model to everything, because we need a\n",
        "  # single model to draw coefficients from, rather than 5\n",
        "  model.fit(X,y)\n",
        "  print(model.classes_)\n",
        "  print(X.shape)\n",
        "  print(model.coef_[0])\n",
        "  print(model.n_iter_)\n",
        "  neg_class_prob_sorted = model.coef_[0, :].argsort()\n",
        "  pos_class_prob_sorted = (-model.coef_[0, :]).argsort()\n",
        "  \n",
        "  termsToTake = 20\n",
        "  pos_indicators = [vocab[i] for i in neg_class_prob_sorted[:termsToTake]]\n",
        "  neg_indicators = [vocab[i] for i in pos_class_prob_sorted[:termsToTake]]\n",
        "\n",
        "  return avg_score,pos_indicators,neg_indicators\n",
        "\n",
        "def evaluateModelL2(X,y,vocab):\n",
        "  return evaluateModel(X,y,vocab,penalty=\"l2\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVwtU7E4QqcN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "237d4a77-2067-47a5-ad28-dffce75d8538"
      },
      "source": [
        "corpus = readReviews()\n",
        "\n",
        "X,y,vocab = createFeatures(corpus)\n",
        "\n",
        "# print(\"L1 norm\")\n",
        "# avg_score,pos_indicators,neg_indicators = evaluateModel(X,y,vocab)\n",
        "\n",
        "# print(\"The model's average accuracy is %f\"%avg_score)\n",
        "# print(\"The most informative terms for neg are: %s\"%pos_indicators)\n",
        "# print(\"The most informative terms for pos are: %s\"%neg_indicators)\n",
        "\n",
        "print(\"L2 norm\")\n",
        "avg_score,pos_indicators,neg_indicators = evaluateModelL2(X,y,vocab)\n",
        "\n",
        "print(\"The model's average accuracy is %f\"%avg_score)\n",
        "print(\"The most informative terms for neg are: %s\"%pos_indicators)\n",
        "print(\"The most informative terms for pos are: %s\"%neg_indicators)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L2 norm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "max_iter reached after 6 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "max_iter reached after 6 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "max_iter reached after 7 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.3s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "max_iter reached after 6 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "max_iter reached after 6 seconds\n",
            "[0.1   0.075 0.1   0.075 0.075]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "max_iter reached after 8 seconds\n",
            "['neg' 'pos']\n",
            "(200, 9141)\n",
            "[-4.27271805e-11  8.01476382e-10  9.33485950e-11 ... -3.33940203e-10\n",
            " -4.93283427e-11  2.06499432e-10]\n",
            "[400]\n",
            "The model's average accuracy is 0.085000\n",
            "The most informative terms for neg are: ['find', 'add', 'camera', 'lawyer', 'total', 'erotic', 'friend', 'named', 'futile', 'homage', 'runs', 'open', 'jeff', 'below', 'jobs', 'maybe', 'realize', 'vengeance', 'band', 'interesting']\n",
            "The most informative terms for pos are: ['redundant', 'shelves', 'proceeds', 'door', 'derivative', 'implied', 'jay', 'obsesses', 'receives', 'maryam', 'stalk', 'typically', 'inexpensive', 'stake', 'interspersed', 'gleason', 'proliferation', 'guesswork', 'narrator', 'stalkers']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.8s finished\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}