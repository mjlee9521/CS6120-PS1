{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PS1-Shakespeare.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOwLHhZktsEm77ZJigzRD7L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mutherr/CS6120-PS1/blob/master/PS1_Shakespeare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdVS67_HNRmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import requests\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate,LeaveOneOut,KFold\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzjMY8fYQbB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read in the shakespeare corpus\n",
        "def readShakespeare():\n",
        "  raw = requests.get(\"https://raw.githubusercontent.com/mutherr/CS6120-PS1-data/master/shakespeare_plays.json\").text.strip()\n",
        "  corpus = [json.loads(line) for line in raw.split(\"\\n\")]\n",
        "\n",
        "  #remove histories from the data, as we're only working with tragedies and comedies\n",
        "  corpus = [entry for entry in corpus if entry[\"genre\"] != \"history\"]\n",
        "  return corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "039fPQcF7OkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here is where you will featurize the data.\n",
        "#NB: The current contents are for testing only\n",
        "#This function should return: \n",
        "#  -a numpy matrix of document features\n",
        "#  -a list of the correct genre for each document\n",
        "#  -a list of the vocabulary used by the features, such that the ith term of the\n",
        "#    list is the word whose counts appear in the ith column of the matrix. \n",
        "def createFeatures(corpus):\n",
        "  from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "  texts = [entry[\"text\"] for entry in corpus]\n",
        "  genres = [entry[\"genre\"] for entry in corpus]\n",
        "\n",
        "  vectorizer = CountVectorizer()\n",
        "  texts = vectorizer.fit_transform(texts)\n",
        "  vocab = vectorizer.get_feature_names()\n",
        "\n",
        "  return texts,genres,vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfTBqBltXe7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#given a numpy matrix representation of the features for the training set, the \n",
        "# vector of true classes for each example, and the vocabulary as described \n",
        "# above, this computes the accuracy of the model using leave one out cross \n",
        "# validation and reports the most indicative features for each class\n",
        "def evaluateModel(X,y,vocab,penalty=\"l1\"):\n",
        "  #create and fit the model\n",
        "  model = LogisticRegression(penalty=penalty,solver=\"liblinear\")\n",
        "  results = cross_validate(model,X,y,cv=LeaveOneOut())\n",
        "  \n",
        "  #determine the average accuracy\n",
        "  scores = results[\"test_score\"]\n",
        "  avg_score = sum(scores)/len(scores)\n",
        "  print(\"The model's average accuracy is %f\"%avg_score)\n",
        "  \n",
        "  #determine the most informative features\n",
        "  # this requires us to fit the model to everything, because we need a\n",
        "  # single model to draw coefficients from, rather than 26\n",
        "  model.fit(X,y)\n",
        "  neg_class_prob_sorted = model.coef_[0, :].argsort()\n",
        "  pos_class_prob_sorted = (-model.coef_[0, :]).argsort()\n",
        "\n",
        "  termsToTake = 20\n",
        "  pos_indicators = [vocab[i] for i in neg_class_prob_sorted[:termsToTake]]\n",
        "  neg_indicators = [vocab[i] for i in pos_class_prob_sorted[:termsToTake]]\n",
        "\n",
        "  return avg_score,pos_indicators,neg_indicators\n",
        "\n",
        "def evaluateModelL2(X,y,vocab):\n",
        "  return evaluateModel(X,y,vocab,penalty=\"l2\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IpJ7PKjvc8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "8aa1a8a7-c05e-40a2-84d1-e0a53d302317"
      },
      "source": [
        "#Run this to read the corpus and fit the model using your featurization scheme\n",
        "\n",
        "corpus = readShakespeare()\n",
        "\n",
        "X,y,vocab = createFeatures(corpus)\n",
        "\n",
        "#this call will fit a model with L1 normalization\n",
        "print(\"----------L1 Norm-----------\")\n",
        "avg_score,pos_indicators,neg_indicators = evaluateModel(X,y,vocab)\n",
        "print(\"The model's average accuracy is %f\"%avg_score)\n",
        "print(\"The most informative terms for comedy are: %s\"%pos_indicators)\n",
        "print(\"The most informative terms for tragedy are: %s\"%neg_indicators)\n",
        "#this call will fit a model with L2 normalization\n",
        "print(\"----------L2 Norm-----------\")\n",
        "avg_score,pos_indicators,neg_indicators = evaluateModelL2(X,y,vocab)\n",
        "print(\"The model's average accuracy is %f\"%avg_score)\n",
        "print(\"The most informative terms for comedy are: %s\"%pos_indicators)\n",
        "print(\"The most informative terms for tragedy are: %s\"%neg_indicators)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.807692\n",
            "The model's average accuracy is 0.807692\n",
            "The most informative terms for comedy are: ['helena', 'prospero', 'sir', 'you', 'your', 'for', 'me', 'duke', 'of', 'love', 'preserver', 'preserved', 'preserve', 'preserv', 'preservation', 'preservers', 'presents', 'presentment', 'presently', 'presenting']\n",
            "The most informative terms for tragedy are: ['our', 'him', 'rom', 'iago', 'thy', 'ham', 'imogen', 'what', 'brutus', 'his', 'lear', 'timon', 'preservers', 'preserver', 'preserved', 'preserv', 'preservative', 'preservation', 'presents', 'presentment']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.730769\n",
            "The model's average accuracy is 0.730769\n",
            "The most informative terms for comedy are: ['you', 'prospero', 'duke', 'helena', 'antonio', 'me', 'for', 'your', 'sir', 'ariel', 'sebastian', 'hermia', 'lysander', 'parolles', 'stephano', 'will', 'leontes', 'caliban', 'demetrius', 'love']\n",
            "The most informative terms for tragedy are: ['ham', 'iago', 'him', 'our', 'othello', 'what', 'his', 'lear', 'imogen', 'brutus', 'rom', 'nurse', 'romeo', 'caesar', 'thy', 'cassio', 'to', 'timon', 'posthumus', 'desdemona']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iHudrPb5NPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}