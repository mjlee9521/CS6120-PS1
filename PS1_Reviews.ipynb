{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PS1-Reviews.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mutherr/CS6120-PS1/blob/master/PS1_Reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdVS67_HNRmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import requests\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate,LeaveOneOut,KFold\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzjMY8fYQbB6",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "# read in the movie review corpus\n",
        "def readReviews():\n",
        "  raw = requests.get(\"https://raw.githubusercontent.com/mutherr/CS6120-PS1-data/master/cornell_reviews.json\").text.strip()\n",
        "  corpus = [json.loads(line) for line in raw.split(\"\\n\")]\n",
        "\n",
        "  return corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "039fPQcF7OkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here is where you will featurize the data.\n",
        "#NB: The current contents are for testing only\n",
        "#This function should return: \n",
        "#  -a numpy matrix of document features\n",
        "#  -a list of the correct genre for each document\n",
        "#  -a list of the vocabulary used by the features, such that the ith term of the\n",
        "#    list is the word whose counts appear in the ith column of the matrix. \n",
        "# This function should return a feature representation using all tokens that\n",
        "# contain an alphabetic character.\n",
        "def createBasicFeatures(corpus):\n",
        "  #Your code here\n",
        "\n",
        "  return texts,genres,vocab\n",
        "\n",
        "# This function can add other features you want that help classification\n",
        "# accuracy, such as bigrams, word prefixes and suffixes, etc.\n",
        "def createFancyFeatures(corpus):\n",
        "  #Your code here\n",
        "\n",
        "  return texts,genres,vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfTBqBltXe7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#given a numpy matrix representation of the features for the training set, the \n",
        "# vector of true classes for each example, and the vocabulary as described \n",
        "# above, this computes the accuracy of the model using leave one out cross \n",
        "# validation and reports the most indicative features for each class\n",
        "\n",
        "def evaluateModel(X,y,vocab,penalty=\"l1\"):\n",
        "  #create and fit the model\n",
        "  model = LogisticRegression(penalty=penalty,solver=\"liblinear\")\n",
        "  results = cross_validate(model,X,y,cv=KFold(n_splits=10, shuffle=True, random_state=1))\n",
        "  \n",
        "  #determine the average accuracy\n",
        "  scores = results[\"test_score\"]\n",
        "  avg_score = sum(scores)/len(scores)\n",
        "  \n",
        "  #determine the most informative features\n",
        "  # this requires us to fit the model to everything, because we need a\n",
        "  # single model to draw coefficients from, rather than 26\n",
        "  model.fit(X,y)\n",
        "  class0_weight_sorted = model.coef_[0, :].argsort()\n",
        "  class1_weight_sorted = (-model.coef_[0, :]).argsort()\n",
        "\n",
        "  termsToTake = 20\n",
        "  class0_indicators = [vocab[i] for i in class0_weight_sorted[:termsToTake]]\n",
        "  class1_indicators = [vocab[i] for i in class1_weight_sorted[:termsToTake]]\n",
        "\n",
        "  if model.classes_[0] == \"pos\":\n",
        "    return avg_score,class0_indicators,class1_indicators\n",
        "  else:\n",
        "    return avg_score,class1_indicators,class0_indicators\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWWq5VgmECKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = readReviews()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IpJ7PKjvc8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Run this to read the corpus and fit the model using your featurization scheme\n",
        "\n",
        "X,y,vocab = createBasicFeatures(corpus)\n",
        "\n",
        "#this call will fit a model with L1 normalization\n",
        "print(\"----------L1 Norm-----------\")\n",
        "avg_score,pos_indicators,neg_indicators = evaluateModel(X,y,vocab,\"l1\")\n",
        "print(\"The model's average accuracy is %f\"%avg_score)\n",
        "print(\"The most informative terms for pos are: %s\"%pos_indicators)\n",
        "print(\"The most informative terms for neg are: %s\"%neg_indicators)\n",
        "#this call will fit a model with L2 normalization\n",
        "print(\"----------L2 Norm-----------\")\n",
        "avg_score,pos_indicators,neg_indicators = evaluateModel(X,y,vocab,\"l2\")\n",
        "print(\"The model's average accuracy is %f\"%avg_score)\n",
        "print(\"The most informative terms for pos are: %s\"%pos_indicators)\n",
        "print(\"The most informative terms for neg are: %s\"%neg_indicators)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iHudrPb5NPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}