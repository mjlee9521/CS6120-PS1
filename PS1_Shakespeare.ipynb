{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PS1-Shakespeare.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNtVSTImaXHaw9cDYbWvU93",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mutherr/CS6120-PS1/blob/master/PS1_Shakespeare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdVS67_HNRmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import requests\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate,LeaveOneOut\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzjMY8fYQbB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read in the shakespeare corpus\n",
        "def readShakespeare():\n",
        "  raw = requests.get(\"https://raw.githubusercontent.com/mutherr/CS6120-PS1/master/shakespeare_plays.json\").text.strip()\n",
        "  corpus = [json.loads(line) for line in raw.split(\"\\n\")]\n",
        "\n",
        "  #remove histories from the data, as we're only working with tragedies and comedies\n",
        "  corpus = [entry for entry in corpus if entry[\"genre\"] != \"history\"]\n",
        "  return corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "039fPQcF7OkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here is where you will featurize the data.\n",
        "# The current contents are for testing only\n",
        "def createFeatures(corpus):\n",
        "  from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "  texts = [entry[\"text\"] for entry in corpus]\n",
        "  genres = [entry[\"genre\"] for entry in corpus]\n",
        "\n",
        "  vectorizer = CountVectorizer()\n",
        "  texts = vectorizer.fit_transform(texts)\n",
        "\n",
        "  return texts,genres,vectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfTBqBltXe7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#given a numpy matrix representation of the features for the training set and the \n",
        "# vector of true classes for each example, this computes the accuracy of the\n",
        "# model using leave one out cross validation and reports the most indicative\n",
        "# features for each class\n",
        "def evaluateModel(X,y,vectorizer,penalty=\"l1\"):\n",
        "  #create and fit the model\n",
        "  model = LogisticRegression(penalty=penalty,solver=\"liblinear\")\n",
        "  results = cross_validate(model,X,y,cv=LeaveOneOut())\n",
        "  \n",
        "  #determine the average accuracy\n",
        "  scores = results[\"test_score\"]\n",
        "  avg_score = sum(scores)/len(scores)\n",
        "  print(\"The model's average accuracy is %f\"%avg_score)\n",
        "  \n",
        "  #determine the most informative features\n",
        "  # this requires us to fit the model to everything, because we need a\n",
        "  # single model to draw coefficients from, rather than 26\n",
        "  model.fit(X,y)\n",
        "  neg_class_prob_sorted = model.coef_[0, :].argsort()\n",
        "  pos_class_prob_sorted = (-model.coef_[0, :]).argsort()\n",
        "\n",
        "  termsToTake = 20\n",
        "  pos_indicators = np.take(vectorizer.get_feature_names(), neg_class_prob_sorted[:termsToTake])\n",
        "  neg_indicators = np.take(vectorizer.get_feature_names(), pos_class_prob_sorted[:termsToTake])\n",
        "\n",
        "  print(\"The most informative terms for comedies are: %s\"%pos_indicators)\n",
        "  print(\"The most informative terms for tragedies are: %s\"%neg_indicators)\n",
        "\n",
        "def evaluateModelL2(X,y,vectorizer):\n",
        "  return evaluateModel(X,y,vectorizer,penalty=\"l2\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IpJ7PKjvc8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "d8366b91-5579-47c3-b7b8-27aef2a46910"
      },
      "source": [
        "#Run this to read the corpus and fit the model using your featurization scheme\n",
        "\n",
        "corpus = readShakespeare()\n",
        "\n",
        "X,y,vectorizer = createFeatures(corpus)\n",
        "\n",
        "print(\"----------L1 Norm-----------\")\n",
        "#this call will fit a model with L1 normalization\n",
        "evaluateModel(X,y,vectorizer)\n",
        "print(\"----------L2 Norm-----------\")\n",
        "#this call will fit a model with L2 normalization\n",
        "evaluateModelL2(X,y,vectorizer)"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.769231\n",
            "The most informative terms for comedies are: ['helena' 'prospero' 'sir' 'you' 'for' 'your' 'me' 'duke' 'of' 'love'\n",
            " 'preserver' 'preserved' 'preserve' 'preserv' 'preservation' 'preservers'\n",
            " 'presents' 'presentment' 'presently' 'presenting']\n",
            "The most informative terms for tragedies are: ['our' 'him' 'rom' 'thy' 'iago' 'ham' 'imogen' 'what' 'brutus' 'his'\n",
            " 'lear' 'timon' 'preservers' 'preserver' 'preserved' 'preserv'\n",
            " 'preservative' 'preservation' 'presents' 'presentment']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.730769\n",
            "The most informative terms for comedies are: ['you' 'prospero' 'duke' 'helena' 'antonio' 'me' 'for' 'your' 'sir'\n",
            " 'ariel' 'sebastian' 'hermia' 'lysander' 'parolles' 'stephano' 'will'\n",
            " 'leontes' 'caliban' 'demetrius' 'love']\n",
            "The most informative terms for tragedies are: ['ham' 'iago' 'him' 'our' 'othello' 'what' 'his' 'lear' 'imogen' 'brutus'\n",
            " 'rom' 'nurse' 'romeo' 'caesar' 'thy' 'cassio' 'to' 'timon' 'posthumus'\n",
            " 'desdemona']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iHudrPb5NPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}