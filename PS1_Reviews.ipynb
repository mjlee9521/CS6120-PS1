{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PS1-Reviews.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMXSnmA8jGih/iw4XEy3K8T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mutherr/CS6120-PS1/blob/master/PS1_Reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un-XooBIC2zt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import requests\n",
        "import torch\n",
        "import random\n",
        "from torch.autograd import Variable\n",
        "from torch.utils import data\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.dataset import random_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkfdQFWZC542",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read in the movie review corpus\n",
        "def readReviews():\n",
        "  raw = requests.get(\"https://raw.githubusercontent.com/mutherr/CS6120-PS1-data/master/cornell_reviews.json\").text.strip()\n",
        "  corpus = [json.loads(line) for line in raw.split(\"\\n\")]\n",
        "  #shuffle the dataset, but always the same way for consistency\n",
        "  random.Random(4).shuffle(corpus)\n",
        "  return corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjlLr0ayRDFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here is where you will featurize the data.\n",
        "#NB: The current contents are for testing only\n",
        "#This function should return: \n",
        "#  -a numpy matrix of document features\n",
        "#  -a list of the correct class for each document\n",
        "#  -a list of the vocabulary used by the features, such that the ith term of the\n",
        "#    list is the word whose counts appear in the ith column of the matrix. \n",
        "def createFeatures(corpus):\n",
        "  from sklearn.feature_extraction.text import CountVectorizer\n",
        "  import string\n",
        "\n",
        "  texts = [entry[\"text\"] for entry in corpus]\n",
        "  genres = [entry[\"class\"] for entry in corpus]\n",
        "\n",
        "  vectorizer = CountVectorizer()\n",
        "  matrix = vectorizer.fit_transform(texts).todense()\n",
        "  vocab = vectorizer.get_feature_names()\n",
        "\n",
        "  return matrix,genres,vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irJ8CxYJREoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model code.\n",
        "class LogisticRegression(torch.nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #outputs = F.softmax(self.linear(x))\n",
        "        outputs = self.linear(x)\n",
        "        return outputs\n",
        "\n",
        "#given a numpy matrix representation of the features for the training set, the \n",
        "# vector of true classes for each example, and the vocabulary as described \n",
        "# above, this computes the accuracy of the model using leave 10-fold cv\n",
        "# validation and reports the most indicative features for each class\n",
        "def evaluateModel(X,y,vocab,penalty=\"l1\"):\n",
        "  #prepare the data for pytorch\n",
        "\n",
        "  #convert y from a list of class names to a list of correct class ids\n",
        "  # (1=pos, 0=neg)\n",
        "  y_binarized = [1 if y[i]==\"pos\" else 0 for i in range(len(y))]\n",
        "\n",
        "  #convert to pytorch tensors and create dataset and loader for the\n",
        "  # train and test sets\n",
        "  tensorX = torch.Tensor(X)\n",
        "  tensorY = torch.LongTensor(y_binarized)\n",
        "  fullDataset = data.TensorDataset(tensorX,tensorY)\n",
        "\n",
        "  train_len = int(len(fullDataset) * 0.9)\n",
        "  trainDataset, testDataset = \\\n",
        "      random_split(fullDataset, [train_len, len(fullDataset) - train_len])\n",
        "\n",
        "  train_loader = data.DataLoader(trainDataset,batch_size=train_len)\n",
        "  test_loader = data.DataLoader(testDataset,batch_size=len(fullDataset) - train_len)\n",
        "\n",
        "  #create the model\n",
        "  #determine input dimensionality (i.e. vocab size)\n",
        "  input_dim = len(vocab)\n",
        "  #known output dim for binary classification task\n",
        "  output_dim = 2\n",
        "\n",
        "  batch_size = train_len\n",
        "  n_iters = 300\n",
        "  epochs = n_iters / (len(trainDataset) / batch_size)\n",
        "  learning_rate = 0.001\n",
        "  model = LogisticRegression(input_dim, output_dim)\n",
        "\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,weight_decay=.1)\n",
        "  \n",
        "  iter = 0\n",
        "  for epoch in range(int(epochs)):\n",
        "      for i, (freqs, labels) in enumerate(train_loader):\n",
        "          freqs = Variable(freqs)\n",
        "          labels = Variable(labels)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(freqs)\n",
        "\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          iter+=1\n",
        "          if iter%50==0:\n",
        "              # calculate Accuracy\n",
        "              correct = 0\n",
        "              total = 0\n",
        "              with torch.no_grad():\n",
        "                for i,(freqs,labels) in enumerate(train_loader):\n",
        "                  freqs = Variable(freqs)\n",
        "                  outputs = model(freqs)\n",
        "                  _, predicted = torch.max(outputs.data, 1)\n",
        "                  total+= labels.size(0)\n",
        "                  correct+= (predicted == labels).sum()\n",
        "              train_accuracy = 100 * correct/total\n",
        "              correct = 0\n",
        "              total = 0\n",
        "              for freqs, labels in test_loader:\n",
        "                  freqs = Variable(freqs)\n",
        "                  outputs = model(freqs)\n",
        "                  _, predicted = torch.max(outputs.data, 1)\n",
        "                  total+= labels.size(0)\n",
        "                  correct+= (predicted == labels).sum()\n",
        "              accuracy = 100 * correct/total\n",
        "              print(\"Iteration: {}. Loss: {}. Train Accuracy: {} Test Accuracy: {}.\".format(iter, loss.item(), train_accuracy, accuracy))\n",
        "  \n",
        "  #get the vocab terms most indicative of each class\n",
        "  params = next(model.parameters())\n",
        "  neg_weights_sorted = params[0, :].argsort()\n",
        "  pos_weights_sorted = params[1, :].argsort()\n",
        "  print(neg_weights_sorted)\n",
        "  print(pos_weights_sorted)\n",
        "\n",
        "  termsToTake = 20\n",
        "  pos_indicators = [vocab[i] for i in pos_weights_sorted[:termsToTake]]\n",
        "  neg_indicators = [vocab[i] for i in neg_weights_sorted[:termsToTake]]\n",
        "  print(pos_indicators)\n",
        "  print(neg_indicators)\n",
        "\n",
        "  #return avg_score,pos_indicators,neg_indicators\n",
        "\n",
        "def evaluateModelL2(X,y,vocab):\n",
        "  return evaluateModel(X,y,vocab,penalty=\"l2\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVwtU7E4QqcN",
        "colab_type": "code",
        "outputId": "f430c6a6-71c0-4545-e665-6299e1ecabf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "corpus = readReviews()\n",
        "\n",
        "X,y,vocab = createFeatures(corpus)\n",
        "\n",
        "# print(\"L1 norm\")\n",
        "# avg_score,pos_indicators,neg_indicators = evaluateModel(X,y,vocab)\n",
        "\n",
        "# print(\"The model's average accuracy is %f\"%avg_score)\n",
        "# print(\"The most informative terms for neg are: %s\"%pos_indicators)\n",
        "# print(\"The most informative terms for pos are: %s\"%neg_indicators)\n",
        "\n",
        "print(\"L2 norm\")\n",
        "avg_score,pos_indicators,neg_indicators = evaluateModelL2(X,y,vocab)\n",
        "\n",
        "print(\"The model's average accuracy is %f\"%avg_score)\n",
        "print(\"The most informative terms for neg are: %s\"%pos_indicators)\n",
        "print(\"The most informative terms for pos are: %s\"%neg_indicators)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L2 norm\n",
            "Iteration: 100. Loss: 0.6931180953979492. Train Accuracy: 51 Test Accuracy: 38.\n",
            "Iteration: 200. Loss: 0.6914469003677368. Train Accuracy: 52 Test Accuracy: 30.\n",
            "Iteration: 300. Loss: 0.6899794340133667. Train Accuracy: 53 Test Accuracy: 23.\n",
            "Iteration: 400. Loss: 0.6886526942253113. Train Accuracy: 53 Test Accuracy: 16.\n",
            "Iteration: 500. Loss: 0.6874317526817322. Train Accuracy: 54 Test Accuracy: 12.\n",
            "Iteration: 600. Loss: 0.6863012313842773. Train Accuracy: 54 Test Accuracy: 9.\n",
            "Iteration: 700. Loss: 0.6852455735206604. Train Accuracy: 54 Test Accuracy: 8.\n",
            "Iteration: 800. Loss: 0.6842538714408875. Train Accuracy: 54 Test Accuracy: 7.\n",
            "Iteration: 900. Loss: 0.6833187341690063. Train Accuracy: 54 Test Accuracy: 5.\n",
            "Iteration: 1000. Loss: 0.682435154914856. Train Accuracy: 55 Test Accuracy: 5.\n",
            "Iteration: 1100. Loss: 0.6815963983535767. Train Accuracy: 55 Test Accuracy: 5.\n",
            "Iteration: 1200. Loss: 0.6807996034622192. Train Accuracy: 55 Test Accuracy: 5.\n",
            "Iteration: 1300. Loss: 0.6800392866134644. Train Accuracy: 55 Test Accuracy: 5.\n",
            "Iteration: 1400. Loss: 0.6793147325515747. Train Accuracy: 55 Test Accuracy: 4.\n",
            "Iteration: 1500. Loss: 0.6786208152770996. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 1600. Loss: 0.6779578328132629. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 1700. Loss: 0.6773207783699036. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 1800. Loss: 0.6767094731330872. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 1900. Loss: 0.6761224269866943. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 2000. Loss: 0.6755568385124207. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 2100. Loss: 0.6750114560127258. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 2200. Loss: 0.6744868159294128. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 2300. Loss: 0.673981249332428. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 2400. Loss: 0.6734922528266907. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 2500. Loss: 0.6730198860168457. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 2600. Loss: 0.6725636720657349. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 2700. Loss: 0.6721225380897522. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 2800. Loss: 0.6716951727867126. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 2900. Loss: 0.6712812781333923. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 3000. Loss: 0.6708806753158569. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 3100. Loss: 0.6704919338226318. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 3200. Loss: 0.6701154112815857. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 3300. Loss: 0.6697505116462708. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 3400. Loss: 0.6693949103355408. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 3500. Loss: 0.6690505743026733. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 3600. Loss: 0.6687167286872864. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 3700. Loss: 0.6683917045593262. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 3800. Loss: 0.6680753827095032. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 3900. Loss: 0.667768120765686. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 4000. Loss: 0.6674690246582031. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 4100. Loss: 0.6671783328056335. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 4200. Loss: 0.6668955087661743. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 4300. Loss: 0.6666194796562195. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 4400. Loss: 0.6663514971733093. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 4500. Loss: 0.6660906076431274. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 4600. Loss: 0.6658357977867126. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 4700. Loss: 0.6655880808830261. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 4800. Loss: 0.6653463244438171. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 4900. Loss: 0.6651099920272827. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 5000. Loss: 0.6648807525634766. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 5100. Loss: 0.6646565794944763. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 5200. Loss: 0.6644372940063477. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 5300. Loss: 0.6642240285873413. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 5400. Loss: 0.664015531539917. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 5500. Loss: 0.6638132929801941. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 5600. Loss: 0.6636142730712891. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 5700. Loss: 0.6634207963943481. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 5800. Loss: 0.6632316708564758. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 5900. Loss: 0.663046658039093. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 6000. Loss: 0.6628664135932922. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 6100. Loss: 0.662689208984375. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 6200. Loss: 0.6625175476074219. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 6300. Loss: 0.6623483896255493. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 6400. Loss: 0.6621837615966797. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 6500. Loss: 0.6620229482650757. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 6600. Loss: 0.6618653535842896. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 6700. Loss: 0.661711573600769. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 6800. Loss: 0.6615610122680664. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 6900. Loss: 0.6614134907722473. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 7000. Loss: 0.6612693071365356. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 7100. Loss: 0.6611285209655762. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 7200. Loss: 0.6609908938407898. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 7300. Loss: 0.6608549952507019. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 7400. Loss: 0.6607226729393005. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 7500. Loss: 0.6605939269065857. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 7600. Loss: 0.6604674458503723. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 7700. Loss: 0.6603437662124634. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 7800. Loss: 0.6602228283882141. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 7900. Loss: 0.6601037383079529. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 8000. Loss: 0.6599858999252319. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 8100. Loss: 0.6598725914955139. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 8200. Loss: 0.6597611904144287. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 8300. Loss: 0.6596512198448181. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 8400. Loss: 0.6595442891120911. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 8500. Loss: 0.6594392657279968. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 8600. Loss: 0.6593366265296936. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 8700. Loss: 0.6592366099357605. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 8800. Loss: 0.6591375470161438. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 8900. Loss: 0.6590406894683838. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 9000. Loss: 0.6589463353157043. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 9100. Loss: 0.6588528156280518. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 9200. Loss: 0.658761739730835. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 9300. Loss: 0.6586723327636719. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 9400. Loss: 0.6585847735404968. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 9500. Loss: 0.6584993600845337. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 9600. Loss: 0.6584137678146362. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 9700. Loss: 0.6583324074745178. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 9800. Loss: 0.6582502722740173. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 9900. Loss: 0.6581714153289795. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 10000. Loss: 0.6580935716629028. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 10100. Loss: 0.6580173969268799. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 10200. Loss: 0.6579423546791077. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 10300. Loss: 0.6578690409660339. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 10400. Loss: 0.6577965617179871. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 10500. Loss: 0.6577263474464417. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 10600. Loss: 0.657656192779541. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 10700. Loss: 0.6575887799263. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 10800. Loss: 0.6575217247009277. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 10900. Loss: 0.6574556231498718. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 11000. Loss: 0.6573929190635681. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 11100. Loss: 0.6573287844657898. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 11200. Loss: 0.6572672128677368. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 11300. Loss: 0.6572057604789734. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 11400. Loss: 0.6571464538574219. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 11500. Loss: 0.6570867300033569. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 11600. Loss: 0.6570303440093994. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 11700. Loss: 0.6569731831550598. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 11800. Loss: 0.6569189429283142. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 11900. Loss: 0.6568633317947388. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 12000. Loss: 0.6568101644515991. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 12100. Loss: 0.6567573547363281. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 12200. Loss: 0.6567068696022034. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 12300. Loss: 0.6566557884216309. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 12400. Loss: 0.6566054821014404. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 12500. Loss: 0.6565572619438171. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 12600. Loss: 0.6565086245536804. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 12700. Loss: 0.6564628481864929. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 12800. Loss: 0.656416654586792. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 12900. Loss: 0.6563712954521179. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 13000. Loss: 0.6563259363174438. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 13100. Loss: 0.656282901763916. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 13200. Loss: 0.6562398076057434. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 13300. Loss: 0.656197190284729. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 13400. Loss: 0.6561558842658997. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 13500. Loss: 0.6561155915260315. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 13600. Loss: 0.6560751795768738. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 13700. Loss: 0.6560356020927429. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 13800. Loss: 0.6559969782829285. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 13900. Loss: 0.655958890914917. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 14000. Loss: 0.6559227108955383. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 14100. Loss: 0.6558858156204224. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 14200. Loss: 0.6558483839035034. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 14300. Loss: 0.6558136940002441. Train Accuracy: 55 Test Accuracy: 3.\n",
            "Iteration: 14400. Loss: 0.6557798385620117. Train Accuracy: 55 Test Accuracy: 3.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}